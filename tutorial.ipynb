{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9f7373-53c6-47e4-b306-8a9f7653abb1",
   "metadata": {},
   "source": [
    "This YOLOv7 ðŸš€ notebook by Vitis AI presents simple train, validate and predict examples to help start your AI adventure.\n",
    "We hope that the resources in this notebook will help you get the most out of YOLOv7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f241107",
   "metadata": {},
   "source": [
    "# Setup and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d6162-9ebd-4b22-a501-a6d069c3d4cc",
   "metadata": {},
   "source": [
    "Clone GitHub repository, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89f5d64-e171-48b6-8ae1-895d3c28edde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://xcdpython.xilinx.com/simple\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages (from -r yolov7/requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages (from -r yolov7/requirements.txt (line 5)) (1.21.6)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "!pip install -r yolov7/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2b49c-4a87-46dd-9f70-c1882c45098e",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141f90a-2b7f-4d1f-a11e-1e288137c7b0",
   "metadata": {},
   "source": [
    "##### Download COCO2017 dataset.(refer to this repo https://github.com/WongKinYiu/yolov7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de1d0c0-2c67-4533-82dd-772f1478055a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip  ...\n",
      "Downloading http://images.cocodataset.org/zips/train2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip ...\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!bash scripts/get_coco.sh\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf86ac7-7152-4574-a819-8d6f719948e1",
   "metadata": {},
   "source": [
    "### After download the coco dataset, the directory structure should be:\n",
    "```markdown\n",
    "+ yolov7/\n",
    "    + coco/\n",
    "        + labels/\n",
    "        + annotations/\n",
    "        + images/\n",
    "        + test-dev2017.txt \n",
    "        + train2017.txt\n",
    "        + val2017.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad3383-46c9-4c19-a6ac-4f163f41b80d",
   "metadata": {},
   "source": [
    "# Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e19ae-3f65-4d82-95f0-ec3e91b9782b",
   "metadata": {},
   "source": [
    "detect.py runs YOLOv7 inference on a variety of sources, downloading models automatically from the latest YOLOv7 release, and saving results to runs/detect. Example inference sources are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66895eed-8b86-4b02-9e9a-6bced791354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/group/dphi_algo_scratch_13/fangyuan/datasets/coco/images/test2017/000000100004.jpg', update=False, view_img=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:1 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:2 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:3 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Model Summary: 392 layers, 36926621 parameters, 36926621 gradients\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "9 cars, 3 trucks, Done. (20.0ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/000000100004.jpg\n",
      "Done. (0.099s)\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source /group/dphi_algo_scratch_13/fangyuan/datasets/coco/images/test2017/000000100004.jpg\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92217f9f-a36b-4045-9f7f-9c5b3effac85",
   "metadata": {},
   "source": [
    "![avatar](./example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a69f4-271e-4759-a412-f6b22f580cc1",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a4d38-906f-4df5-af62-ba9674242dc6",
   "metadata": {},
   "source": [
    "## Eval float model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07455fb0-f2fa-433a-874c-f132c30c11cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=False, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Model Summary: 392 layers, 36926621 parameters, 36926621 gradients\n",
      " Convert model to Traced-model... \n",
      " model is traced! \n",
      "\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335       0.718       0.638       0.689       0.495\n",
      "Speed: 20.9/0.9/21.8 ms inference/NMS/total per 640x640 image at batch-size 1\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/test/yolov7_640_val/yolov7_predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=4.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=55.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=11.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "Results saved to runs/test/yolov7_640_val\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "# for float training\n",
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights yolov7.pt --name yolov7_640_val --quant_mode float\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230681a",
   "metadata": {},
   "source": [
    "## Eval  Post-training quanzization model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34f168",
   "metadata": {},
   "source": [
    "### Run calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb6b3c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=False, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Model Summary: 392 layers, 36926621 parameters, 36926621 gradients\n",
      " Convert model to Traced-model... \n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- xcdl190200\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.12.1\n",
      "        vai_q_pytorch --- 3.0.0+1bbeff9+torch1.12.1\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2622.1\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(nndct/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      " model is traced! \n",
      "\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(nndct/quant_info.json)\u001b[0m\n",
      "                 all        1000        7117       0.684       0.638       0.677        0.43\n",
      "Speed: 370.3/1.0/371.3 ms inference/NMS/total per 640x640 image at batch-size 1\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/test/yolov7_640_val2/yolov7_predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=18.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      "Results saved to runs/test/yolov7_640_val2\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights yolov7.pt --name yolov7_640_val --quant_mode calib --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec0607",
   "metadata": {},
   "source": [
    "### run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebab65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=False, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Model Summary: 392 layers, 36926621 parameters, 36926621 gradients\n",
      " Convert model to Traced-model... \n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- xcdl190200\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.12.1\n",
      "        vai_q_pytorch --- 3.0.0+1bbeff9+torch1.12.1\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2236.4\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(nndct/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      " model is traced! \n",
      "\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/onnx/utils.py:1523: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input Model::input_0\n",
      "  key\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/prim_ops.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not (list(self.node.out_tensors[0].shape[1:]) == list(input.size())[1:]):\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/torchquantizer.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inf.sum() > 0 or nan.sum() > 0:\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/fix_ops.py:69: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tensor.storage().size() != tensor.numel()):\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.onnx is generated.(nndct/Model_int.onnx)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.pt is generated.(nndct/Model_int.pt)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Converting to xmodel ...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Dumping 'Model_0'' checking data...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finsh dumping data.(nndct/deploy_check_data_int/Model_0)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Successfully convert 'Model_0' to xmodel.(nndct/Model_0_int.xmodel)\u001b[0m\n",
      "                 all        5000       36335        0.68       0.594       0.637       0.392\n",
      "Speed: 98.7/1.0/99.6 ms inference/NMS/total per 640x640 image at batch-size 1\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/test/yolov7_640_val3/yolov7_predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.44s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=6.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=65.60s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=14.80s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754\n",
      "Results saved to runs/test/yolov7_640_val3\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights yolov7.pt --name yolov7_640_val --quant_mode test --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3d91a",
   "metadata": {},
   "source": [
    "### dump model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807d58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=False, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Model Summary: 392 layers, 36926621 parameters, 36926621 gradients\n",
      " Convert model to Traced-model... \n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- xcdl190200\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.12.1\n",
      "        vai_q_pytorch --- 3.0.0+1bbeff9+torch1.12.1\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2534.6\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Doing weights equalization...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(nndct/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      " model is traced! \n",
      "\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/onnx/utils.py:1523: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input Model::input_0\n",
      "  key\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/prim_ops.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not (list(self.node.out_tensors[0].shape[1:]) == list(input.size())[1:]):\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/torchquantizer.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inf.sum() > 0 or nan.sum() > 0:\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/fix_ops.py:69: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tensor.storage().size() != tensor.numel()):\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.onnx is generated.(nndct/Model_int.onnx)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.pt is generated.(nndct/Model_int.pt)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Converting to xmodel ...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Dumping 'Model_0'' checking data...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finsh dumping data.(nndct/deploy_check_data_int/Model_0)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Successfully convert 'Model_0' to xmodel.(nndct/Model_0_int.xmodel)\u001b[0m\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights yolov7.pt --name yolov7_640_val --quant_mode test --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish --dump_model\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b235516",
   "metadata": {},
   "source": [
    "## Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92fefb6-598a-438a-866f-2cb9b374788d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'yolov7/'\n",
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:1 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:2 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "                               CUDA:3 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0,1,2,3', entity=None, epochs=300, evolve=False, exist_ok=False, freeze=[0], global_rank=0, hyp='data/hyp.scratch.p5_qat.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=0, log_threshold_scale=100.0, multi_scale=False, name='yolov7_qat', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov7_qat2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, v5_metric=False, weights='yolov7.pt', workers=8, world_size=4)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0001, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "RepConv.fuse_repvgg_block\n",
      "Model Summary: 432 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "RepConv.fuse_repvgg_block\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "IDetect.fuse\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "IDetect.fuse\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 417 layers, 36929178 parameters, 36929178 gradients, 105.2 GFLOPS\n",
      "Transferred 522/536 items from yolov7.pt\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 1175.4\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2841.8\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 92 .bias, 92 conv.weight, 92 other\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017.cache' images and labels... 117266 found, 1021 m\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "                                                  | 407/? [00:00<00:00, 1620.96i\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 1253.4\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 1260.2\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 953.29\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2835.6\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2859.4\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2770.5\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017.cache' images and labels... 117266 found, 1021 m\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017.cache' images and labels... 117266 found, 1021 m\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017.cache' images and labels... 117266 found, 1021 m\u001b[0m\n",
      "anchors/target = 4.42, Best Possible Recall (BPR) = 0.9912\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/yolov7_qat2\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "  0%|                                                  | 0/3697 [00:00<?, ?it/s]^C\n",
      "  0%|                                                  | 0/3697 [00:20<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train_qat.py\", line 675, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"train_qat.py\", line 675, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"train_qat.py\", line 399, in train\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"train_qat.py\", line 399, in train\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    output = self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 969, in _run_ddp_forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n",
      "    return module_to_run(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    output = self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 969, in _run_ddp_forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "    return module_to_run(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/utils/torch_utils.py\", line 605, in forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/utils/torch_utils.py\", line 605, in forward\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 8229 closing signal SIGINT\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 8230 closing signal SIGINT\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 8231 closing signal SIGINT\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 8232 closing signal SIGINT\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 599, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 627, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/common.py\", line 113, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/module_transform.py\", line 74, in _forward_hook\n",
      "    return self.output_quantizer(output)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 216, in forward\n",
      "    return self._forward_fn(x, self.log_threshold, self.domain, self.method)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 202, in _quantize_with_warmup\n",
      "    log_threshold.data[0] = torch.log2(self._init_threshold(x))[0]\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 190, in _init_threshold\n",
      "    th = init_scheme[self.tensor_type](data)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 182, in _kl_j\n",
      "    d_tmp = calculate_kl_j(cdf[np.nonzero(cdf)], q[np.nonzero(cdf)])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 148, in calculate_kl_j\n",
      "    return np.sum((x - y) * np.log2(x / y))\n",
      "KeyboardInterrupt\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 599, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 627, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/common.py\", line 113, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/module_transform.py\", line 74, in _forward_hook\n",
      "    return self.output_quantizer(output)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 216, in forward\n",
      "    return self._forward_fn(x, self.log_threshold, self.domain, self.method)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 202, in _quantize_with_warmup\n",
      "    log_threshold.data[0] = torch.log2(self._init_threshold(x))[0]\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 190, in _init_threshold\n",
      "    th = init_scheme[self.tensor_type](data)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 182, in _kl_j\n",
      "    d_tmp = calculate_kl_j(cdf[np.nonzero(cdf)], q[np.nonzero(cdf)])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 148, in calculate_kl_j\n",
      "    return np.sum((x - y) * np.log2(x / y))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train_qat.py\", line 675, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"train_qat.py\", line 399, in train\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n",
      "    output = self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 969, in _run_ddp_forward\n",
      "    return module_to_run(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/utils/torch_utils.py\", line 605, in forward\n",
      "    x = instance.origin_forward(x)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 599, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 627, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/common.py\", line 113, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/module_transform.py\", line 74, in _forward_hook\n",
      "    return self.output_quantizer(output)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 216, in forward\n",
      "    return self._forward_fn(x, self.log_threshold, self.domain, self.method)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 202, in _quantize_with_warmup\n",
      "    log_threshold.data[0] = torch.log2(self._init_threshold(x))[0]\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train_qat.py\", line 675, in <module>\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"train_qat.py\", line 399, in train\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 1008, in forward\n",
      "    output = self._run_ddp_forward(*inputs, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 969, in _run_ddp_forward\n",
      "    return module_to_run(*inputs[0], **kwargs[0])\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/utils/torch_utils.py\", line 605, in forward\n",
      "    x = instance.origin_forward(x)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 599, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/yolo.py\", line 627, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspace/internal-models/pytorch/yolov7/yolov7/models/common.py\", line 113, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n",
      "    hook_result = hook(self, input, result)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/module_transform.py\", line 74, in _forward_hook\n",
      "    return self.output_quantizer(output)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 216, in forward\n",
      "    return self._forward_fn(x, self.log_threshold, self.domain, self.method)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 202, in _quantize_with_warmup\n",
      "    log_threshold.data[0] = torch.log2(self._init_threshold(x))[0]\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 190, in _init_threshold\n",
      "    th = init_scheme[self.tensor_type](data)\n",
      "  File \"/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/quantization/modules/tqt.py\", line 151, in _kl_j\n",
      "    mx = np.max(np.abs(x))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python -m torch.distributed.launch --nproc_per_node 4 --master_port 9004 train_qat.py --workers 8 --device 0,1,2,3 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights yolov7.pt --name yolov7_qat --hyp data/hyp.scratch.p5_qat.yaml --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish --log_threshold_scale 100\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29480b8b",
   "metadata": {},
   "source": [
    "## Eval QAT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c42ece",
   "metadata": {},
   "source": [
    "### run quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c70fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=True, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['../quantized/qat.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 417 layers, 36929178 parameters, 36929178 gradients, 105.2 GFLOPS\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 1040.1\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2786.5\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_DEPRECATED_ARGUMENT]: \"convert_to_deployable\" is deprecated and will be removed in the future. Use \"to_deployable\" instead.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2734.0\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.0.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.0.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.1.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.1.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.2.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.2.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.3.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.3.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.4.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.4.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.5.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.5.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.6.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.6.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.7.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.7.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.8.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.8.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.9.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.9.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.11.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.11.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.13.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.13.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.14.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.14.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.15.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.15.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.17.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.17.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.18.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.18.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.19.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.19.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.20.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.20.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.21.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.21.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.22.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.22.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.24.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.24.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.26.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.26.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.27.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.27.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.28.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.28.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.30.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.30.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.31.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.31.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.32.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.32.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.33.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.33.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.34.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.34.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.35.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.35.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.37.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.37.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.39.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.39.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.40.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.40.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.41.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.41.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.43.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.43.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.44.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.44.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.45.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.45.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.46.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.46.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.47.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.47.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.48.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.48.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.50.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.50.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv1.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv1.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv3.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv3.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv4.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv4.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv5.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv5.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv6.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv6.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv2.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv2.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv7.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv7.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.52.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.52.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.54.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.54.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.56.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.56.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.57.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.57.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.58.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.58.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.59.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.59.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.60.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.60.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.61.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.61.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.63.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.63.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.64.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.64.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.66.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.66.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.68.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.68.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.69.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.69.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.70.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.70.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.71.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.71.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.72.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.72.conv.bias.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.73.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.73.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.75.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.75.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.77.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.77.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.78.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.78.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.79.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.79.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.81.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.81.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.82.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.82.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.83.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.83.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.84.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.84.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.85.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.85.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.86.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.86.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.88.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.88.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.90.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.90.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.91.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.91.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.92.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.92.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.94.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.94.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.95.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.95.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.96.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.96.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.97.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.97.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.98.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.98.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.99.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.99.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.101.conv.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.101.conv.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.102.rbr_reparam.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.102.rbr_reparam.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.103.rbr_reparam.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.103.rbr_reparam.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.104.rbr_reparam.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.104.rbr_reparam.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.0.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.0.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.1.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.1.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.2.weight.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.2.bias.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/QuantStub[quant]/10757.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[0]/Conv2d[conv]/ret.5.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[0]/Hardswish[act]/ret.9.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[1]/Conv2d[conv]/ret.11.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[1]/Hardswish[act]/ret.15.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[2]/Conv2d[conv]/ret.17.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[2]/Hardswish[act]/ret.21.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[3]/Conv2d[conv]/ret.23.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[3]/Hardswish[act]/ret.27.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[4]/Conv2d[conv]/ret.29.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[10]/Cat[cat]/ret.65.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[5]/Conv2d[conv]/ret.35.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[5]/Hardswish[act]/ret.39.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[6]/Conv2d[conv]/ret.41.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[6]/Hardswish[act]/ret.45.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[7]/Conv2d[conv]/ret.47.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[7]/Hardswish[act]/ret.51.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[8]/Conv2d[conv]/ret.53.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[8]/Hardswish[act]/ret.57.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[9]/Conv2d[conv]/ret.59.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[11]/Conv2d[conv]/ret.67.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[11]/Hardswish[act]/ret.71.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[12]/MaxPool2d[m]/11098.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[13]/Conv2d[conv]/ret.73.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[16]/Cat[cat]/ret.91.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[14]/Conv2d[conv]/ret.79.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[14]/Hardswish[act]/ret.83.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[15]/Conv2d[conv]/ret.85.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[17]/Conv2d[conv]/ret.93.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[23]/Cat[cat]/ret.129.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[18]/Conv2d[conv]/ret.99.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[18]/Hardswish[act]/ret.103.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[19]/Conv2d[conv]/ret.105.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[19]/Hardswish[act]/ret.109.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[20]/Conv2d[conv]/ret.111.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[20]/Hardswish[act]/ret.115.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[21]/Conv2d[conv]/ret.117.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[21]/Hardswish[act]/ret.121.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[22]/Conv2d[conv]/ret.123.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[24]/Conv2d[conv]/ret.131.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[24]/Hardswish[act]/ret.135.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[25]/MaxPool2d[m]/11412.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[26]/Conv2d[conv]/ret.137.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[29]/Cat[cat]/ret.155.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[27]/Conv2d[conv]/ret.143.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[27]/Hardswish[act]/ret.147.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[28]/Conv2d[conv]/ret.149.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[30]/Conv2d[conv]/ret.157.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[36]/Cat[cat]/ret.193.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[31]/Conv2d[conv]/ret.163.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[31]/Hardswish[act]/ret.167.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[32]/Conv2d[conv]/ret.169.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[32]/Hardswish[act]/ret.173.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[33]/Conv2d[conv]/ret.175.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[33]/Hardswish[act]/ret.179.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[34]/Conv2d[conv]/ret.181.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[34]/Hardswish[act]/ret.185.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[35]/Conv2d[conv]/ret.187.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[37]/Conv2d[conv]/ret.195.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[37]/Hardswish[act]/ret.199.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[38]/MaxPool2d[m]/11726.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[39]/Conv2d[conv]/ret.201.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[42]/Cat[cat]/ret.219.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[40]/Conv2d[conv]/ret.207.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[40]/Hardswish[act]/ret.211.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[41]/Conv2d[conv]/ret.213.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[43]/Conv2d[conv]/ret.221.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[49]/Cat[cat]/ret.257.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[44]/Conv2d[conv]/ret.227.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[44]/Hardswish[act]/ret.231.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[45]/Conv2d[conv]/ret.233.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[45]/Hardswish[act]/ret.237.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[46]/Conv2d[conv]/ret.239.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[46]/Hardswish[act]/ret.243.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[47]/Conv2d[conv]/ret.245.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[47]/Hardswish[act]/ret.249.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[48]/Conv2d[conv]/ret.251.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[50]/Conv2d[conv]/ret.259.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[50]/Hardswish[act]/ret.263.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv1]/Conv2d[conv]/ret.265.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv1]/Hardswish[act]/ret.269.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv3]/Conv2d[conv]/ret.271.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv3]/Hardswish[act]/ret.275.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv4]/Conv2d[conv]/ret.277.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv4]/Hardswish[act]/ret.281.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Cat[cat]/ret.283.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv5]/Conv2d[conv]/ret.285.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv5]/Hardswish[act]/ret.289.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv6]/Conv2d[conv]/ret.291.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Cat[cat2]/ret.303.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv2]/Conv2d[conv]/ret.297.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv7]/Conv2d[conv]/ret.305.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv7]/Hardswish[act]/ret.309.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[52]/Conv2d[conv]/ret.311.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[52]/Hardswish[act]/ret.315.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[55]/Cat[cat]/ret.325.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[54]/Conv2d[conv]/ret.319.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[56]/Conv2d[conv]/ret.327.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[62]/Cat[cat]/ret.363.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[57]/Conv2d[conv]/ret.333.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[57]/Hardswish[act]/ret.337.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[58]/Conv2d[conv]/ret.339.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[58]/Hardswish[act]/ret.343.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[59]/Conv2d[conv]/ret.345.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[59]/Hardswish[act]/ret.349.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[60]/Conv2d[conv]/ret.351.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[60]/Hardswish[act]/ret.355.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[61]/Conv2d[conv]/ret.357.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[63]/Conv2d[conv]/ret.365.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[63]/Hardswish[act]/ret.369.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[64]/Conv2d[conv]/ret.371.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[64]/Hardswish[act]/ret.375.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[67]/Cat[cat]/ret.385.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[66]/Conv2d[conv]/ret.379.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[68]/Conv2d[conv]/ret.387.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[74]/Cat[cat]/ret.423.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[69]/Conv2d[conv]/ret.393.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[69]/Hardswish[act]/ret.397.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[70]/Conv2d[conv]/ret.399.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[70]/Hardswish[act]/ret.403.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[71]/Conv2d[conv]/ret.405.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[71]/Hardswish[act]/ret.409.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[72]/Conv2d[conv]/ret.411.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[72]/Hardswish[act]/ret.415.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[73]/Conv2d[conv]/ret.417.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[75]/Conv2d[conv]/ret.425.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[75]/Hardswish[act]/ret.429.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[76]/MaxPool2d[m]/12849.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[77]/Conv2d[conv]/ret.431.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[80]/Cat[cat]/ret.449.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[78]/Conv2d[conv]/ret.437.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[78]/Hardswish[act]/ret.441.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[79]/Conv2d[conv]/ret.443.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[81]/Conv2d[conv]/ret.451.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[87]/Cat[cat]/ret.487.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[82]/Conv2d[conv]/ret.457.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[82]/Hardswish[act]/ret.461.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[83]/Conv2d[conv]/ret.463.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[83]/Hardswish[act]/ret.467.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[84]/Conv2d[conv]/ret.469.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[84]/Hardswish[act]/ret.473.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[85]/Conv2d[conv]/ret.475.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[85]/Hardswish[act]/ret.479.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[86]/Conv2d[conv]/ret.481.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[88]/Conv2d[conv]/ret.489.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[88]/Hardswish[act]/ret.493.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[89]/MaxPool2d[m]/13163.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[90]/Conv2d[conv]/ret.495.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[93]/Cat[cat]/ret.513.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[91]/Conv2d[conv]/ret.501.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[91]/Hardswish[act]/ret.505.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[92]/Conv2d[conv]/ret.507.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[94]/Conv2d[conv]/ret.515.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[100]/Cat[cat]/ret.551.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[95]/Conv2d[conv]/ret.521.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[95]/Hardswish[act]/ret.525.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[96]/Conv2d[conv]/ret.527.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[96]/Hardswish[act]/ret.531.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[97]/Conv2d[conv]/ret.533.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[97]/Hardswish[act]/ret.537.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[98]/Conv2d[conv]/ret.539.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[98]/Hardswish[act]/ret.543.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[99]/Conv2d[conv]/ret.545.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[101]/Conv2d[conv]/ret.553.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[101]/Hardswish[act]/ret.557.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[102]/Conv2d[rbr_reparam]/ret.559.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[102]/Hardswish[act]/ret.561.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[103]/Conv2d[rbr_reparam]/ret.563.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[103]/Hardswish[act]/ret.565.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[104]/Conv2d[rbr_reparam]/ret.567.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[104]/Hardswish[act]/ret.569.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[0]/ret.571.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[1]/ret.575.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[2]/ret.579.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(nndct/test/quant_info.json)\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(nndct/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.102.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 20\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.103.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 21\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.104.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 21\u001b[0m\n",
      " Convert model to Traced-model... \n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- xcdl190200\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.12.1\n",
      "        vai_q_pytorch --- 3.0.0+1bbeff9+torch1.12.1\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2358.6\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(nndct/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      " model is traced! \n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/onnx/utils.py:1523: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input Model::input_0\n",
      "  key\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/prim_ops.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not (list(self.node.out_tensors[0].shape[1:]) == list(input.size())[1:]):\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/torchquantizer.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inf.sum() > 0 or nan.sum() > 0:\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/fix_ops.py:69: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tensor.storage().size() != tensor.numel()):\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.onnx is generated.(nndct/Model_int.onnx)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.pt is generated.(nndct/Model_int.pt)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Converting to xmodel ...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Dumping 'Model_0'' checking data...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finsh dumping data.(nndct/deploy_check_data_int/Model_0)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Successfully convert 'Model_0' to xmodel.(nndct/Model_0_int.xmodel)\u001b[0m\n",
      "                 all        5000       36335       0.739       0.614        0.67       0.463\n",
      "Speed: 104.1/1.1/105.2 ms inference/NMS/total per 640x640 image at batch-size 1\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/test/yolov7_640_val5/qat_predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=4.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=57.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=10.51s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.498\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n",
      "Results saved to runs/test/yolov7_640_val5\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights ../quantized/qat.pt --name yolov7_640_val --quant_mode test --nndct_qat --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499b0a1",
   "metadata": {},
   "source": [
    "### dump QAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "867a8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/internal-models/pytorch/yolov7/yolov7\n",
      "Namespace(augment=False, batch_size=1, conf_thres=0.001, data='data/coco.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_640_val', nndct_qat=True, no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['../quantized/qat.pt'])\n",
      "YOLOR ðŸš€ ef59292b3 torch 1.12.1 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
      "\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Loading NNDCT kernels...\u001b[0m\n",
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 417 layers, 36929178 parameters, 36929178 gradients, 105.2 GFLOPS\n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization calibration process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 1151.2\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(.vai_qat/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2818.1\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_DEPRECATED_ARGUMENT]: \"convert_to_deployable\" is deprecated and will be removed in the future. Use \"to_deployable\" instead.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2795.6\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(.vai_qat/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.0.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.0.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.1.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.1.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.2.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.2.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.3.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.3.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.4.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.4.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.5.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.5.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.6.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.6.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.7.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.7.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.8.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.8.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.9.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.9.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.11.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.11.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.13.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.13.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.14.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.14.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.15.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.15.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.17.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.17.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.18.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.18.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.19.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.19.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.20.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.20.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.21.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.21.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.22.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.22.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.24.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.24.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.26.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.26.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.27.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.27.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.28.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.28.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.30.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.30.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.31.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.31.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.32.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.32.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.33.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.33.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.34.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.34.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.35.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.35.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.37.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.37.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.39.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.39.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.40.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.40.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.41.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.41.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.43.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.43.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.44.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.44.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.45.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.45.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.46.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.46.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.47.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.47.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.48.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.48.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.50.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.50.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv1.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv1.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv3.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv3.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv4.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv4.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv5.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv5.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv6.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv6.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv2.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv2.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv7.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.51.cv7.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.52.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.52.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.54.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.54.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.56.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.56.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.57.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.57.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.58.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.58.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.59.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.59.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.60.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.60.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.61.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.61.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.63.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.63.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.64.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.64.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.66.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.66.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.68.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.68.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.69.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.69.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.70.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.70.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.71.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.71.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.72.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.72.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.73.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.73.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.75.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.75.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.77.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.77.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.78.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.78.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.79.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.79.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.81.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.81.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.82.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.82.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.83.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.83.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.84.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.84.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.85.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.85.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.86.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.86.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.88.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.88.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.90.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.90.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.91.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.91.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.92.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.92.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.94.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.94.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.95.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.95.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.96.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.96.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.97.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.97.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.98.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.98.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.99.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.99.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.101.conv.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.101.conv.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.102.rbr_reparam.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.102.rbr_reparam.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.103.rbr_reparam.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.103.rbr_reparam.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.104.rbr_reparam.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.104.rbr_reparam.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.0.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.0.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.1.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.1.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.2.weight.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::model.105.m.2.bias.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/QuantStub[quant]/10757.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[0]/Conv2d[conv]/ret.5.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[0]/Hardswish[act]/ret.9.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[1]/Conv2d[conv]/ret.11.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[1]/Hardswish[act]/ret.15.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[2]/Conv2d[conv]/ret.17.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[2]/Hardswish[act]/ret.21.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[3]/Conv2d[conv]/ret.23.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[3]/Hardswish[act]/ret.27.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[4]/Conv2d[conv]/ret.29.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[10]/Cat[cat]/ret.65.\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[5]/Conv2d[conv]/ret.35.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[5]/Hardswish[act]/ret.39.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[6]/Conv2d[conv]/ret.41.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[6]/Hardswish[act]/ret.45.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[7]/Conv2d[conv]/ret.47.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[7]/Hardswish[act]/ret.51.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[8]/Conv2d[conv]/ret.53.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[8]/Hardswish[act]/ret.57.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[9]/Conv2d[conv]/ret.59.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[11]/Conv2d[conv]/ret.67.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[11]/Hardswish[act]/ret.71.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[12]/MaxPool2d[m]/11098.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[13]/Conv2d[conv]/ret.73.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[16]/Cat[cat]/ret.91.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[14]/Conv2d[conv]/ret.79.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[14]/Hardswish[act]/ret.83.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[15]/Conv2d[conv]/ret.85.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[17]/Conv2d[conv]/ret.93.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[23]/Cat[cat]/ret.129.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[18]/Conv2d[conv]/ret.99.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[18]/Hardswish[act]/ret.103.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[19]/Conv2d[conv]/ret.105.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[19]/Hardswish[act]/ret.109.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[20]/Conv2d[conv]/ret.111.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[20]/Hardswish[act]/ret.115.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[21]/Conv2d[conv]/ret.117.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[21]/Hardswish[act]/ret.121.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[22]/Conv2d[conv]/ret.123.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[24]/Conv2d[conv]/ret.131.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[24]/Hardswish[act]/ret.135.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[25]/MaxPool2d[m]/11412.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[26]/Conv2d[conv]/ret.137.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[29]/Cat[cat]/ret.155.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[27]/Conv2d[conv]/ret.143.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[27]/Hardswish[act]/ret.147.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[28]/Conv2d[conv]/ret.149.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[30]/Conv2d[conv]/ret.157.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[36]/Cat[cat]/ret.193.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[31]/Conv2d[conv]/ret.163.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[31]/Hardswish[act]/ret.167.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[32]/Conv2d[conv]/ret.169.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[32]/Hardswish[act]/ret.173.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[33]/Conv2d[conv]/ret.175.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[33]/Hardswish[act]/ret.179.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[34]/Conv2d[conv]/ret.181.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[34]/Hardswish[act]/ret.185.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[35]/Conv2d[conv]/ret.187.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[37]/Conv2d[conv]/ret.195.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[37]/Hardswish[act]/ret.199.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[38]/MaxPool2d[m]/11726.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[39]/Conv2d[conv]/ret.201.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[42]/Cat[cat]/ret.219.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[40]/Conv2d[conv]/ret.207.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[40]/Hardswish[act]/ret.211.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[41]/Conv2d[conv]/ret.213.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[43]/Conv2d[conv]/ret.221.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[49]/Cat[cat]/ret.257.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[44]/Conv2d[conv]/ret.227.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[44]/Hardswish[act]/ret.231.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[45]/Conv2d[conv]/ret.233.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[45]/Hardswish[act]/ret.237.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[46]/Conv2d[conv]/ret.239.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[46]/Hardswish[act]/ret.243.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[47]/Conv2d[conv]/ret.245.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[47]/Hardswish[act]/ret.249.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[48]/Conv2d[conv]/ret.251.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[50]/Conv2d[conv]/ret.259.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[50]/Hardswish[act]/ret.263.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv1]/Conv2d[conv]/ret.265.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv1]/Hardswish[act]/ret.269.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv3]/Conv2d[conv]/ret.271.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv3]/Hardswish[act]/ret.275.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv4]/Conv2d[conv]/ret.277.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv4]/Hardswish[act]/ret.281.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Cat[cat]/ret.283.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv5]/Conv2d[conv]/ret.285.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv5]/Hardswish[act]/ret.289.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv6]/Conv2d[conv]/ret.291.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Cat[cat2]/ret.303.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv2]/Conv2d[conv]/ret.297.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv7]/Conv2d[conv]/ret.305.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/SPPCSPC[model]/SPPCSPC[51]/Conv[cv7]/Hardswish[act]/ret.309.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[52]/Conv2d[conv]/ret.311.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[52]/Hardswish[act]/ret.315.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[55]/Cat[cat]/ret.325.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[54]/Conv2d[conv]/ret.319.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[56]/Conv2d[conv]/ret.327.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[62]/Cat[cat]/ret.363.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[57]/Conv2d[conv]/ret.333.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[57]/Hardswish[act]/ret.337.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[58]/Conv2d[conv]/ret.339.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[58]/Hardswish[act]/ret.343.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[59]/Conv2d[conv]/ret.345.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[59]/Hardswish[act]/ret.349.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[60]/Conv2d[conv]/ret.351.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[60]/Hardswish[act]/ret.355.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[61]/Conv2d[conv]/ret.357.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[63]/Conv2d[conv]/ret.365.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[63]/Hardswish[act]/ret.369.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[64]/Conv2d[conv]/ret.371.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[64]/Hardswish[act]/ret.375.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[67]/Cat[cat]/ret.385.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[66]/Conv2d[conv]/ret.379.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[68]/Conv2d[conv]/ret.387.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[74]/Cat[cat]/ret.423.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[69]/Conv2d[conv]/ret.393.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[69]/Hardswish[act]/ret.397.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[70]/Conv2d[conv]/ret.399.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[70]/Hardswish[act]/ret.403.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[71]/Conv2d[conv]/ret.405.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[71]/Hardswish[act]/ret.409.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[72]/Conv2d[conv]/ret.411.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[72]/Hardswish[act]/ret.415.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[73]/Conv2d[conv]/ret.417.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[75]/Conv2d[conv]/ret.425.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[75]/Hardswish[act]/ret.429.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[76]/MaxPool2d[m]/12849.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[77]/Conv2d[conv]/ret.431.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[80]/Cat[cat]/ret.449.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[78]/Conv2d[conv]/ret.437.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[78]/Hardswish[act]/ret.441.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[79]/Conv2d[conv]/ret.443.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[81]/Conv2d[conv]/ret.451.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[87]/Cat[cat]/ret.487.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[82]/Conv2d[conv]/ret.457.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[82]/Hardswish[act]/ret.461.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[83]/Conv2d[conv]/ret.463.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[83]/Hardswish[act]/ret.467.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[84]/Conv2d[conv]/ret.469.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[84]/Hardswish[act]/ret.473.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[85]/Conv2d[conv]/ret.475.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[85]/Hardswish[act]/ret.479.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[86]/Conv2d[conv]/ret.481.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[88]/Conv2d[conv]/ret.489.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[88]/Hardswish[act]/ret.493.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/MP[model]/MP[89]/MaxPool2d[m]/13163.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[90]/Conv2d[conv]/ret.495.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[93]/Cat[cat]/ret.513.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[91]/Conv2d[conv]/ret.501.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[91]/Hardswish[act]/ret.505.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[92]/Conv2d[conv]/ret.507.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[94]/Conv2d[conv]/ret.515.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Concat[model]/Concat[100]/Cat[cat]/ret.551.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[95]/Conv2d[conv]/ret.521.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[95]/Hardswish[act]/ret.525.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[96]/Conv2d[conv]/ret.527.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[96]/Hardswish[act]/ret.531.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[97]/Conv2d[conv]/ret.533.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[97]/Hardswish[act]/ret.537.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[98]/Conv2d[conv]/ret.539.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[98]/Hardswish[act]/ret.543.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[99]/Conv2d[conv]/ret.545.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[101]/Conv2d[conv]/ret.553.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/Conv[model]/Conv[101]/Hardswish[act]/ret.557.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[102]/Conv2d[rbr_reparam]/ret.559.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[102]/Hardswish[act]/ret.561.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[103]/Conv2d[rbr_reparam]/ret.563.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[103]/Hardswish[act]/ret.565.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[104]/Conv2d[rbr_reparam]/ret.567.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/RepConv[model]/RepConv[104]/Hardswish[act]/ret.569.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[0]/ret.571.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[1]/ret.575.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SCALE_VALUE]: Exported scale values are not trained: Model::Model/NNDctDetect[model]/NNDctDetect[105]/Conv2d[m]/ModuleList[2]/ret.579.\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(nndct/test/quant_info.json)\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Exporting quant config.(nndct/quant_info.json)\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.102.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 20\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.103.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 21\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_SHIFT_CHECK]: bias Model::model.104.rbr_reparam.bias value is too small, so adjust the fix position from 26 to 21\u001b[0m\n",
      " Convert model to Traced-model... \n",
      "freezing model.105.ia.0.implicit\n",
      "freezing model.105.ia.1.implicit\n",
      "freezing model.105.ia.2.implicit\n",
      "freezing model.105.im.0.implicit\n",
      "freezing model.105.im.1.implicit\n",
      "freezing model.105.im.2.implicit\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: OS and CPU information:\n",
      "               system --- Linux\n",
      "                 node --- xcdl190200\n",
      "              release --- 4.4.0-134-generic\n",
      "              version --- #160-Ubuntu SMP Wed Aug 15 14:58:00 UTC 2018\n",
      "              machine --- x86_64\n",
      "            processor --- x86_64\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Tools version information:\n",
      "                  GCC --- GCC 9.4.0\n",
      "               python --- 3.7.12\n",
      "              pytorch --- 1.12.1\n",
      "        vai_q_pytorch --- 3.0.0+1bbeff9+torch1.12.1\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: GPU information:\n",
      "          device name --- Tesla P100-PCIE-16GB\n",
      "     device available --- True\n",
      "         device count --- 1\n",
      "       current device --- 0\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quant config file is empty, use default quant configuration\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Quantization test process start up...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quant Module is in 'cuda'.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Parsing Model...\u001b[0m\n",
      "\n",
      "\u001b[0;33m[VAIQ_WARN][QUANTIZER_TORCH_REPLACE_SILU]: SiLU has been replaced by Hardswish.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Start to trace and freeze model...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: The input model Model is torch.nn.Module.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Finish tracing.\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Processing ops...\u001b[0m\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 2757.1\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Quantizable module is generated.(nndct/Model.py)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Get module with quantization.\u001b[0m\n",
      " model is traced! \n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017.cache' images and labels... 4952 found, 48 missing, \u001b[0m\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/torch/onnx/utils.py:1523: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input Model::input_0\n",
      "  key\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/prim_ops.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not (list(self.node.out_tensors[0].shape[1:]) == list(input.size())[1:]):\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/quantization/torchquantizer.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if inf.sum() > 0 or nan.sum() > 0:\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-pytorch/lib/python3.7/site-packages/pytorch_nndct/nn/modules/fix_ops.py:69: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  tensor.storage().size() != tensor.numel()):\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.onnx is generated.(nndct/Model_int.onnx)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: Model_int.pt is generated.(nndct/Model_int.pt)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Converting to xmodel ...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Dumping 'Model_0'' checking data...\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Finsh dumping data.(nndct/deploy_check_data_int/Model_0)\u001b[0m\n",
      "\n",
      "\u001b[0;32m[VAIQ_NOTE]: =>Successfully convert 'Model_0' to xmodel.(nndct/Model_0_int.xmodel)\u001b[0m\n",
      "/workspace/internal-models/pytorch/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7/\n",
    "!python test_nndct.py --data data/coco.yaml --img 640 --batch 1 --conf 0.001 --iou 0.65 --device 0 --weights ../quantized/qat.pt --name yolov7_640_val --quant_mode test --nndct_qat --nndct_convert_sigmoid_to_hsigmoid --nndct_convert_silu_to_hswish --dump_model\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34f8af-a6b2-4c5d-96ac-7f6ef206f514",
   "metadata": {},
   "source": [
    "## Performance\n",
    "| Model             | Input Size | Float mAP   | Quant mAP   | QAT mAP   | FLOPs  |\n",
    "|-------------------|------------|-------------|-------------|-------------|--------|\n",
    "| YOLOv7           | 640\\*640   | 50.9%       | 40.8%       | 47.9%       | 104.8G  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
